import streamlit as st
import joblib
from newspaper import Article, Config
from bs4 import BeautifulSoup
import requests
import time
from datetime import datetime

# --- Page Config ---
st.set_page_config(
    page_title="Fake News Detector", 
    page_icon="üì∞", 
    layout="centered",
    initial_sidebar_state="expanded"
)

# --- Load Model with Cache and Error Handling ---
@st.cache_resource(show_spinner="Loading detection model...")
def load_model():
    try:
        model = joblib.load("logistic_model.pkl")
        vectorizer = joblib.load("tfidf_vectorizer.pkl")
        return model, vectorizer
    except Exception as e:
        st.error(f"Failed to load model: {str(e)}")
        st.stop()

log_model, tfidf_vectorizer = load_model()

# --- Classification Function ---
def classify_article(text):
    """Classify text and return prediction with confidence scores"""
    vect_text = tfidf_vectorizer.transform([text])
    prediction = log_model.predict(vect_text)[0]
    probabilities = log_model.predict_proba(vect_text)[0]
    return prediction, probabilities

# --- Enhanced URL Extraction with Timeout ---
def extract_text_from_url(url, timeout=10):
    """Extract article text with fallback mechanisms"""
    config = Config()
    config.browser_user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
    config.request_timeout = timeout
    
    extraction_methods = [
        lambda: newspaper_extract(url, config),
        lambda: bs4_extract(url, config)
    ]
    
    for method in extraction_methods:
        try:
            result = method()
            if result and len(result.split()) > 50:  # Minimum 50 words
                return result
        except Exception:
            continue
    return None

def newspaper_extract(url, config):
    """Primary extraction using newspaper3k"""
    article = Article(url, config=config)
    article.download()
    article.parse()
    return article.text

def bs4_extract(url, config):
    """Fallback extraction using BeautifulSoup"""
    headers = {"User-Agent": config.browser_user_agent}
    res = requests.get(url, headers=headers, timeout=config.request_timeout)
    soup = BeautifulSoup(res.content, "html.parser")
    return " ".join(p.get_text() for p in soup.find_all("p"))

# --- Modern UI Components ---
def render_header():
    st.markdown("""
    <div style="
        background: linear-gradient(135deg, #002B5B 0%, #1A5F7A 100%); 
        padding: 1.5rem; 
        border-radius: 15px; 
        margin-bottom: 2rem; 
        box-shadow: 0 4px 20px rgba(0,0,0,0.1);
    ">
        <h1 style="
            color: white; 
            text-align: center; 
            font-family: 'Poppins', sans-serif; 
            font-weight: 600; 
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
        ">üß† AI-Powered Fake News Detector</h1>
        <p style="
            color: rgba(255,255,255,0.9); 
            text-align: center; 
            font-family: 'Poppins', sans-serif; 
            font-size: 1rem;
        ">Analyze news articles for authenticity in real time</p>
    </div>
    """, unsafe_allow_html=True)

def render_sidebar():
    with st.sidebar:
        st.markdown("### About This Tool")
        st.markdown("""
        - **AI/ML Model**: Logistic Regression with TF-IDF
        - **Accuracy**: 94.7% on test data
        - **Training Data**: 44,889 political articles
        """)
        
        st.markdown("### How to Use")
        st.markdown("""
        1. Paste text or enter URL
        2. Click Analyze
        3. Review results
        """)
        
        st.divider()
        st.markdown(f"**Last Updated**: {datetime.now().strftime('%Y-%m-%d')}")
        st.caption("For academic/research purposes only")

# --- Main App Flow ---
def main():
    render_header()
    render_sidebar()
    
    # Input Tabs
    tab1, tab2 = st.tabs(["üìù Paste Article Text", "üîó Enter Article URL"])
    text_input = ""
    
    with tab1:
        text_input = st.text_area(
            "Paste article text:", 
            height=250,
            placeholder="Paste the full article text here...",
            help="For best results, include at least 3 paragraphs"
        )
    
    with tab2:
        url_input = st.text_input(
            "Enter article URL:",
            placeholder="https://example.com/news-article",
            help="Supports most news websites"
        )
        if url_input:
            with st.status("üîÑ Extracting article content...", expanded=True) as status:
                try:
                    start_time = time.time()
                    article_text = extract_text_from_url(url_input)
                    
                    if article_text:
                        text_input = article_text
                        status.update(
                            label=f"‚úÖ Extracted {len(article_text.split())} words in {time.time()-start_time:.1f}s", 
                            state="complete"
                        )
                        st.text_area("Extracted content:", article_text, height=200)
                    else:
                        status.update(label="‚ùå Failed to extract meaningful content", state="error")
                except Exception as e:
                    status.update(label=f"‚ö†Ô∏è Error: {str(e)}", state="error")
    
    # Analysis Section
    if st.button("üîç Analyze Article", type="primary", use_container_width=True):
        if not text_input.strip():
            st.warning("Please enter some article text first")
        else:
            with st.spinner("üß† Analyzing content..."):
                # Simulate processing time for better UX
                progress_bar = st.progress(0)
                for percent in range(0, 101, 5):
                    time.sleep(0.05)
                    progress_bar.progress(percent)
                
                prediction, probabilities = classify_article(text_input)
                confidence = round(max(probabilities) * 100, 2)
                
                # Enhanced Results Display
                st.markdown("---")
                st.subheader("üîç Analysis Results")
                
                result_col, confidence_col = st.columns([3, 1])
                with result_col:
                    if prediction == 1:
                        st.success(f"## ‚úÖ Likely Real News")
                    else:
                        st.error(f"## üö® Likely Fake News")
                
                with confidence_col:
                    st.metric("Confidence", f"{confidence}%")
                
                # Confidence Visualization
                confidence_color = (
                    "#2ecc71" if confidence > 70 else
                    "#f39c12" if confidence > 50 else
                    "#e74c3c"
                )
                
                st.markdown(f"""
                <div style="
                    background: {confidence_color}20;
                    border-left: 4px solid {confidence_color};
                    padding: 1rem;
                    border-radius: 0 8px 8px 0;
                    margin: 1rem 0;
                ">
                    <p style="margin: 0; font-weight: 500;">Model Confidence: <strong>{confidence}%</strong></p>
                    <div style="height: 8px; background: linear-gradient(90deg, {confidence_color} {confidence}%, #ecf0f1 {confidence}%); margin-top: 0.5rem;"></div>
                </div>
                """, unsafe_allow_html=True)
                
                # Explanation Section
                with st.expander("üìä Detailed Analysis", expanded=True):
                    if prediction == 1:
                        st.markdown("""
                        ### Characteristics of Real News:
                        - **Balanced Language**: Neutral tone with minimal sensationalism
                        - **Credible Sources**: References to verifiable sources
                        - **Fact-Based**: Presents evidence and multiple perspectives
                        """)
                    else:
                        st.markdown("""
                        ### Warning Signs Detected:
                        - **Emotional Language**: Excessive use of charged words
                        - **Lack of Sources**: Few or no credible references
                        - **Absolutes**: Overuse of "always", "never", etc.
                        """)
                    
                    st.markdown("""
                    #### Next Steps:
                    1. Cross-check with fact-checking resources below
                    2. Compare with other news sources
                    3. Consider the publication's reputation
                    """)
                
                # Resources Section
                st.markdown("### üîç Verify With Trusted Sources")
                cols = st.columns(3)
                resources = [
                    ("FactCheck.org", "https://www.factcheck.org/", "#1abc9c"),
                    ("Snopes", "https://www.snopes.com/", "#3498db"), 
                    ("PolitiFact", "https://www.politifact.com/", "#e74c3c")
                ]
                
                for col, (name, url, color) in zip(cols, resources):
                    with col:
                        st.markdown(f"""
                        <a href="{url}" target="_blank" style="
                            display: block;
                            padding: 0.5rem;
                            background: {color}20;
                            border-radius: 8px;
                            text-align: center;
                            color: {color};
                            text-decoration: none;
                            border: 1px solid {color}40;
                        ">
                            {name}
                        </a>
                        """, unsafe_allow_html=True)
                
                # Disclaimer
                st.caption("‚ö†Ô∏è This analysis is algorithmic and should be verified by human judgment")

if __name__ == "__main__":
    main()
